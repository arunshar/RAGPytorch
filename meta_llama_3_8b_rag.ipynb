{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunshar/RAGPytorch/blob/main/meta_llama_3_8b_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a225ac6b",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-04-19T06:42:22.946821Z",
          "iopub.status.busy": "2024-04-19T06:42:22.946502Z",
          "iopub.status.idle": "2024-04-19T06:44:30.979557Z",
          "shell.execute_reply": "2024-04-19T06:44:30.978470Z"
        },
        "papermill": {
          "duration": 128.040533,
          "end_time": "2024-04-19T06:44:30.981879",
          "exception": false,
          "start_time": "2024-04-19T06:42:22.941346",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a225ac6b",
        "outputId": "b2706350-8bcd-4202-c892-6bdcb5d2860b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.1.2\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.3/670.2 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:17\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install \"torch==2.1.2\" tensorboard\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade \\\n",
        "  \"transformers==4.38.2\" \\\n",
        "  \"datasets==2.16.1\" \\\n",
        "  \"accelerate==0.26.1\" \\\n",
        "  \"evaluate==0.4.1\" \\\n",
        "  \"bitsandbytes==0.42.0\" \\\n",
        "  \"trl==0.7.11\" \\\n",
        "  \"peft==0.8.2\" \\\n",
        "    \"langchain\" \\\n",
        "\"sentence-transformers\" \\\n",
        "\"faiss-cpu\"\n",
        "!pip install unstructured\n",
        "!pip install pdfminer\n",
        "!pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a39dcf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:44:31.030362Z",
          "iopub.status.busy": "2024-04-19T06:44:31.029699Z",
          "iopub.status.idle": "2024-04-19T06:44:31.251383Z",
          "shell.execute_reply": "2024-04-19T06:44:31.250558Z"
        },
        "papermill": {
          "duration": 0.247887,
          "end_time": "2024-04-19T06:44:31.253564",
          "exception": false,
          "start_time": "2024-04-19T06:44:31.005677",
          "status": "completed"
        },
        "tags": [],
        "id": "81a39dcf"
      },
      "outputs": [],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "hf_token = user_secrets.get_secret(\"hf_token\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47573e23",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:44:31.301892Z",
          "iopub.status.busy": "2024-04-19T06:44:31.301629Z",
          "iopub.status.idle": "2024-04-19T06:46:35.880194Z",
          "shell.execute_reply": "2024-04-19T06:46:35.879283Z"
        },
        "papermill": {
          "duration": 124.604752,
          "end_time": "2024-04-19T06:46:35.882370",
          "exception": false,
          "start_time": "2024-04-19T06:44:31.277618",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "bd493a71b7704a2eb48ecc8bcd954ad2",
            "f0b766f582594134b8a77312a1b375f9",
            "b5a49b165e3146e3822edfc9f6ad1cf5",
            "dfd07630bd7a49429d464a9e6a6fae7a",
            "b99d32a532a7474687f086ae4474468a",
            "fd2eda48075e45c3bc55d773da99509c",
            "0ced44a045ce4fde84eb149fd6f766aa",
            "d1dbbfb3a8214954add46849bdef47aa",
            "dd2efc898f5e45038acde4a505fc63d0",
            "cfebec61eddd4ffe9d2ce3ddd6cb657e",
            "283b44844de0413d9ac5a9d05751ab3f",
            "5a786aeeaaf042beaca829f89884be5e"
          ]
        },
        "id": "47573e23",
        "outputId": "659cba0f-ed8d-488e-d3e4-2267be3151a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-19 06:44:38.634319: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-19 06:44:38.634423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-19 06:44:38.762394: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd493a71b7704a2eb48ecc8bcd954ad2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0b766f582594134b8a77312a1b375f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5a49b165e3146e3822edfc9f6ad1cf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfd07630bd7a49429d464a9e6a6fae7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b99d32a532a7474687f086ae4474468a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd2eda48075e45c3bc55d773da99509c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ced44a045ce4fde84eb149fd6f766aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1dbbfb3a8214954add46849bdef47aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd2efc898f5e45038acde4a505fc63d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/126 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfebec61eddd4ffe9d2ce3ddd6cb657e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "283b44844de0413d9ac5a9d05751ab3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a786aeeaaf042beaca829f89884be5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from IPython.display import display_markdown\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import pipeline\n",
        "import transformers\n",
        "from langchain.document_loaders import UnstructuredPDFLoader,PDFMinerLoader,TextLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,token=hf_token,\n",
        "    model_kwargs={\n",
        "        \"torch_dtype\": torch.float16,\n",
        "        \"quantization_config\": {\"load_in_4bit\": True},\n",
        "        \"low_cpu_mem_usage\": True,\n",
        "    },\n",
        ")\n",
        "\n",
        "terminators =  [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf798f5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:46:35.935425Z",
          "iopub.status.busy": "2024-04-19T06:46:35.934827Z",
          "iopub.status.idle": "2024-04-19T06:46:35.939009Z",
          "shell.execute_reply": "2024-04-19T06:46:35.938173Z"
        },
        "papermill": {
          "duration": 0.03204,
          "end_time": "2024-04-19T06:46:35.940965",
          "exception": false,
          "start_time": "2024-04-19T06:46:35.908925",
          "status": "completed"
        },
        "tags": [],
        "id": "bf798f5c"
      },
      "outputs": [],
      "source": [
        "### Pdf file Path for RAG\n",
        "pdf_file_path = \"/kaggle/input/deep-learning-ian-goodfellow/DeepLearningBook.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbebf966",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:46:35.992075Z",
          "iopub.status.busy": "2024-04-19T06:46:35.991432Z",
          "iopub.status.idle": "2024-04-19T06:46:35.998494Z",
          "shell.execute_reply": "2024-04-19T06:46:35.997585Z"
        },
        "papermill": {
          "duration": 0.034681,
          "end_time": "2024-04-19T06:46:36.000339",
          "exception": false,
          "start_time": "2024-04-19T06:46:35.965658",
          "status": "completed"
        },
        "tags": [],
        "id": "bbebf966"
      },
      "outputs": [],
      "source": [
        "class Llama3_8B_gen:\n",
        "    def __init__(self,pipeline):\n",
        "        self.pipeline= pipeline\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_prompt(query,retrieved_text):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"Answer the Question for the Given below context and information and not prior knowledge, only give the output result \\n\\ncontext:\\n\\n{}\".format(retrieved_text) },\n",
        "            {\"role\": \"user\", \"content\": query},]\n",
        "        return pipeline.tokenizer.apply_chat_template(messages, tokenize=False,add_generation_prompt=True)\n",
        "\n",
        "    def generate(self,query,retrieved_context):\n",
        "        prompt = self.generate_prompt(query ,retrieved_context)\n",
        "        output =  pipeline(prompt,max_new_tokens=512,eos_token_id=terminators,do_sample=True,\n",
        "                            temperature=0.7,top_p=0.9,)\n",
        "        return output[0][\"generated_text\"][len(prompt):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c8a792",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:46:36.055020Z",
          "iopub.status.busy": "2024-04-19T06:46:36.054289Z",
          "iopub.status.idle": "2024-04-19T06:46:36.061899Z",
          "shell.execute_reply": "2024-04-19T06:46:36.061076Z"
        },
        "papermill": {
          "duration": 0.036493,
          "end_time": "2024-04-19T06:46:36.063739",
          "exception": false,
          "start_time": "2024-04-19T06:46:36.027246",
          "status": "completed"
        },
        "tags": [],
        "id": "01c8a792"
      },
      "outputs": [],
      "source": [
        "class Langchain_RAG:\n",
        "    def __init__(self,pdf_file_path):\n",
        "        self.embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "        self.pdf_file_path = pdf_file_path\n",
        "        print(\"loading pdf file , this may take time to process\")\n",
        "        self.loader = loader = PDFMinerLoader(self.pdf_file_path)\n",
        "        self.data = self.loader.load()\n",
        "        print(\"<< pdf file loaded\")\n",
        "        print(\"<< chunking\")\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"])\n",
        "        self.texts = text_splitter.split_documents(self.data)\n",
        "        print(\"<< chunked\")\n",
        "        self.get_vec_value= FAISS.from_documents(self.texts, self.embeddings)\n",
        "        print(\"<< saved\")\n",
        "        self.retriever = self.get_vec_value.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "    def __call__(self,query):\n",
        "        rev = self.retriever.get_relevant_documents(query)\n",
        "        return \"\".join([i.page_content for i in rev])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3303fe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:46:36.123381Z",
          "iopub.status.busy": "2024-04-19T06:46:36.123011Z",
          "iopub.status.idle": "2024-04-19T06:51:23.499482Z",
          "shell.execute_reply": "2024-04-19T06:51:23.498336Z"
        },
        "papermill": {
          "duration": 287.409096,
          "end_time": "2024-04-19T06:51:23.501712",
          "exception": false,
          "start_time": "2024-04-19T06:46:36.092616",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "0646c5755a2e46e8934e160da277d6d0",
            "904de97faca74c25be2338ea9f8638f7",
            "e7d33ad817de424d8aab062c2864fec5",
            "b11df588c877451cac388327cb1211a5",
            "9729029c36334d4ab19b53b99dd67a8e",
            "66380a4e0dcb414ba19986630fd3d4e5",
            "0c5f68ff4abd4442a5db66b4dddc84b3",
            "8736cd9e3f4a44f890657614004c3092",
            "cbf4efe6f0fd42ad842015326fae9ce8",
            "85ffb53bdd3d4f92a1d133729dd29540",
            "a8ec7bdaf8244e21be9e778db0f8a524"
          ]
        },
        "id": "7e3303fe",
        "outputId": "42e7256d-ffa5-4bb4-d86f-1df152448bf9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0646c5755a2e46e8934e160da277d6d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "904de97faca74c25be2338ea9f8638f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7d33ad817de424d8aab062c2864fec5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b11df588c877451cac388327cb1211a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9729029c36334d4ab19b53b99dd67a8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66380a4e0dcb414ba19986630fd3d4e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c5f68ff4abd4442a5db66b4dddc84b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8736cd9e3f4a44f890657614004c3092",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbf4efe6f0fd42ad842015326fae9ce8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85ffb53bdd3d4f92a1d133729dd29540",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8ec7bdaf8244e21be9e778db0f8a524",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading pdf file , this may take time to process\n",
            "<< pdf file loaded\n",
            "<< chunking\n",
            "<< chunked\n",
            "<< saved\n"
          ]
        }
      ],
      "source": [
        "text_gen = Llama3_8B_gen(pipeline=pipeline)\n",
        "retriever = Langchain_RAG(pdf_file_path=pdf_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a27877",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:51:23.558008Z",
          "iopub.status.busy": "2024-04-19T06:51:23.557653Z",
          "iopub.status.idle": "2024-04-19T06:51:23.562280Z",
          "shell.execute_reply": "2024-04-19T06:51:23.561371Z"
        },
        "papermill": {
          "duration": 0.034979,
          "end_time": "2024-04-19T06:51:23.564110",
          "exception": false,
          "start_time": "2024-04-19T06:51:23.529131",
          "status": "completed"
        },
        "tags": [],
        "id": "16a27877"
      },
      "outputs": [],
      "source": [
        "def Rag_qa(query):\n",
        "    retriever_context = retriever(query)\n",
        "    resut = text_gen.generate(query,retriever_context)\n",
        "    return resut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8016c869",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:51:23.620575Z",
          "iopub.status.busy": "2024-04-19T06:51:23.620305Z",
          "iopub.status.idle": "2024-04-19T06:51:31.456564Z",
          "shell.execute_reply": "2024-04-19T06:51:31.455594Z"
        },
        "papermill": {
          "duration": 7.866351,
          "end_time": "2024-04-19T06:51:31.458656",
          "exception": false,
          "start_time": "2024-04-19T06:51:23.592305",
          "status": "completed"
        },
        "tags": [],
        "id": "8016c869",
        "outputId": "8b7d2791-0bf6-4baf-c16a-87d1d0ed43a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Deep learning is an approach to machine learning that has drawn heavily on our knowledge of the human brain, statistics and applied math. Specifically, it is a type of machine learning, a technique that allows computer systems to improve with experience and data."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_markdown(Rag_qa(\"What is Deep Learning?\"),raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27696aef",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T06:51:31.516567Z",
          "iopub.status.busy": "2024-04-19T06:51:31.515971Z",
          "iopub.status.idle": "2024-04-19T06:52:09.104509Z",
          "shell.execute_reply": "2024-04-19T06:52:09.103527Z"
        },
        "papermill": {
          "duration": 37.649416,
          "end_time": "2024-04-19T06:52:09.136488",
          "exception": false,
          "start_time": "2024-04-19T06:51:31.487072",
          "status": "completed"
        },
        "tags": [],
        "id": "27696aef",
        "outputId": "234af6d3-b8a5-49d3-ab4b-41e9924b4824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "A Convolutional Neural Network (CNN) is a type of neural network architecture that is particularly well-suited for processing data with grid-like topology, such as images. The key idea behind CNNs is to leverage the spatial relationships between pixels in an image to improve performance on image-related tasks.\n",
              "\n",
              "A CNN typically consists of multiple layers, each of which performs a specific function:\n",
              "\n",
              "1. **Convolutional Layer**: This layer applies a set of filters to the input data, scanning the data in a sliding window fashion. Each filter learns to detect specific features, such as edges or textures, in the input data. The filters are typically small, 3x3 or 5x5, and are applied in a hierarchical manner, allowing the network to capture features at multiple scales.\n",
              "2. **Activation Function**: After the convolutional layer, an activation function is applied to introduce non-linearity into the network. Common activation functions include ReLU (Rectified Linear Unit), Sigmoid, and Tanh.\n",
              "3. **Pooling Layer**: The pooling layer reduces the spatial dimensions of the input data, allowing the network to capture larger features and reducing the number of parameters. Common pooling functions include Max Pooling and Average Pooling.\n",
              "4. **Flattening**: The output of the convolutional and pooling layers is flattened into a 1D vector, which is then fed into the fully connected layers.\n",
              "5. **Fully Connected Layers**: The flattened output is fed into one or more fully connected layers, which are similar to traditional neural networks. These layers learn to recognize more complex features and patterns.\n",
              "\n",
              "The key innovations in CNNs are:\n",
              "\n",
              "* **Parameter sharing**: CNNs share the same set of filters across the input data, which reduces the number of parameters and improves generalization.\n",
              "* **Spatial hierarchy**: CNNs build a spatial hierarchy of features, allowing them to capture features at multiple scales and resolutions.\n",
              "* **Translation equivariance**: CNNs are designed to be translation equivariant, meaning that the output is unaffected by the position of the input data.\n",
              "\n",
              "CNNs have been extremely successful in various computer vision tasks, such as image classification, object detection, and segmentation. They have also been used in natural language processing tasks, such as text classification and machine translation."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_markdown(Rag_qa(\"Explain Convotional Neural Network.\"),raw=True)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4573380,
          "sourceId": 7808810,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4828888,
          "sourceId": 8161765,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 592.456117,
      "end_time": "2024-04-19T06:52:12.609283",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-19T06:42:20.153166",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}